{"cells":[{"cell_type":"markdown","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n","\n","<h1 align=\"center\"><font size=\"5\">Supervised Machine Learning: Regression - Final Assignment</font></h1>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Instructions:\n","\n","In this Assignment, you will demonstrate the data regression skills you have learned by completing this course. You are expected to leverage a wide variety of tools, but also this report should focus on present findings, insights, and next steps. You may include some visuals from your code output, but this report is intended as a summary of your findings, not as a code review. \n","\n","The grading will center around 5 main points:\n","\n","1. Does the report include a section describing the data?\n","2. Does the report include a paragraph detailing the main objective(s) of this analysis? \n","3. Does the report include a section with variations of linear regression models and specifies which one is the model that best suits the main objective(s) of this analysis.\n","4. Does the report include a clear and well-presented section with key findings related to the main objective(s) of the analysis?\n","5. Does the report highlight possible flaws in the model and a plan of action to revisit this analysis with additional data or different predictive modeling techniques? \n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Import the required libraries\n"]},{"cell_type":"markdown","metadata":{},"source":["The following required modules are pre-installed in the Skills Network Labs environment. However if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda) you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n","# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n","# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import sklearn as skl\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{},"source":["## Importing the Dataset\n"]},{"cell_type":"markdown","metadata":{},"source":["Before you begin, you will need to choose a data set that you feel passionate about. You can brainstorm with your peers about great public data sets using the discussion board in this module.\n"]},{"cell_type":"markdown","metadata":{},"source":["Read your chosen dataset into pandas dataframe:\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>communityName</th>\n","      <th>state</th>\n","      <th>countyCode</th>\n","      <th>communityCode</th>\n","      <th>population</th>\n","      <th>householdsize</th>\n","      <th>racepctblack</th>\n","      <th>racePctWhite</th>\n","      <th>racePctAsian</th>\n","      <th>racePctHisp</th>\n","      <th>...</th>\n","      <th>burglaries</th>\n","      <th>burglPerPop</th>\n","      <th>larcenies</th>\n","      <th>larcPerPop</th>\n","      <th>autoTheft</th>\n","      <th>autoTheftPerPop</th>\n","      <th>arsons</th>\n","      <th>arsonsPerPop</th>\n","      <th>ViolentCrimesPerPop</th>\n","      <th>nonViolPerPop</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BerkeleyHeightstownship</td>\n","      <td>NJ</td>\n","      <td>39.0</td>\n","      <td>5320.0</td>\n","      <td>11980</td>\n","      <td>3.10</td>\n","      <td>1.37</td>\n","      <td>91.78</td>\n","      <td>6.50</td>\n","      <td>1.88</td>\n","      <td>...</td>\n","      <td>14.0</td>\n","      <td>114.85</td>\n","      <td>138.0</td>\n","      <td>1132.08</td>\n","      <td>16.0</td>\n","      <td>131.26</td>\n","      <td>2.0</td>\n","      <td>16.41</td>\n","      <td>41.02</td>\n","      <td>1394.59</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Marpletownship</td>\n","      <td>PA</td>\n","      <td>45.0</td>\n","      <td>47616.0</td>\n","      <td>23123</td>\n","      <td>2.82</td>\n","      <td>0.80</td>\n","      <td>95.57</td>\n","      <td>3.44</td>\n","      <td>0.85</td>\n","      <td>...</td>\n","      <td>57.0</td>\n","      <td>242.37</td>\n","      <td>376.0</td>\n","      <td>1598.78</td>\n","      <td>26.0</td>\n","      <td>110.55</td>\n","      <td>1.0</td>\n","      <td>4.25</td>\n","      <td>127.56</td>\n","      <td>1955.95</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Tigardcity</td>\n","      <td>OR</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>29344</td>\n","      <td>2.43</td>\n","      <td>0.74</td>\n","      <td>94.33</td>\n","      <td>3.43</td>\n","      <td>2.35</td>\n","      <td>...</td>\n","      <td>274.0</td>\n","      <td>758.14</td>\n","      <td>1797.0</td>\n","      <td>4972.19</td>\n","      <td>136.0</td>\n","      <td>376.30</td>\n","      <td>22.0</td>\n","      <td>60.87</td>\n","      <td>218.59</td>\n","      <td>6167.51</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gloversvillecity</td>\n","      <td>NY</td>\n","      <td>35.0</td>\n","      <td>29443.0</td>\n","      <td>16656</td>\n","      <td>2.40</td>\n","      <td>1.70</td>\n","      <td>97.35</td>\n","      <td>0.50</td>\n","      <td>0.70</td>\n","      <td>...</td>\n","      <td>225.0</td>\n","      <td>1301.78</td>\n","      <td>716.0</td>\n","      <td>4142.56</td>\n","      <td>47.0</td>\n","      <td>271.93</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>306.64</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Bemidjicity</td>\n","      <td>MN</td>\n","      <td>7.0</td>\n","      <td>5068.0</td>\n","      <td>11245</td>\n","      <td>2.76</td>\n","      <td>0.53</td>\n","      <td>89.16</td>\n","      <td>1.17</td>\n","      <td>0.52</td>\n","      <td>...</td>\n","      <td>91.0</td>\n","      <td>728.93</td>\n","      <td>1060.0</td>\n","      <td>8490.87</td>\n","      <td>91.0</td>\n","      <td>728.93</td>\n","      <td>5.0</td>\n","      <td>40.05</td>\n","      <td>NaN</td>\n","      <td>9988.79</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 146 columns</p>\n","</div>"],"text/plain":["             communityName state  countyCode  communityCode  population  \\\n","0  BerkeleyHeightstownship    NJ        39.0         5320.0       11980   \n","1           Marpletownship    PA        45.0        47616.0       23123   \n","2               Tigardcity    OR         NaN            NaN       29344   \n","3         Gloversvillecity    NY        35.0        29443.0       16656   \n","4              Bemidjicity    MN         7.0         5068.0       11245   \n","\n","   householdsize  racepctblack  racePctWhite  racePctAsian  racePctHisp  ...  \\\n","0           3.10          1.37         91.78          6.50         1.88  ...   \n","1           2.82          0.80         95.57          3.44         0.85  ...   \n","2           2.43          0.74         94.33          3.43         2.35  ...   \n","3           2.40          1.70         97.35          0.50         0.70  ...   \n","4           2.76          0.53         89.16          1.17         0.52  ...   \n","\n","   burglaries  burglPerPop  larcenies  larcPerPop  autoTheft  autoTheftPerPop  \\\n","0        14.0       114.85      138.0     1132.08       16.0           131.26   \n","1        57.0       242.37      376.0     1598.78       26.0           110.55   \n","2       274.0       758.14     1797.0     4972.19      136.0           376.30   \n","3       225.0      1301.78      716.0     4142.56       47.0           271.93   \n","4        91.0       728.93     1060.0     8490.87       91.0           728.93   \n","\n","   arsons  arsonsPerPop  ViolentCrimesPerPop  nonViolPerPop  \n","0     2.0         16.41                41.02        1394.59  \n","1     1.0          4.25               127.56        1955.95  \n","2    22.0         60.87               218.59        6167.51  \n","3     NaN           NaN               306.64            NaN  \n","4     5.0         40.05                  NaN        9988.79  \n","\n","[5 rows x 146 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('crimedata.csv')\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["In the EDA notebook, we have already performed an extensive analysis to select the appropriate features for this regression analysis. For the regression analysis, we are only going to concentrate on **predicting violent crime rates** for a given community. We will filter our dataframe by the columns that shown the highest correlation with violent crime rates straight away."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["selected_cols = ['PctKidsBornNeverMar', 'nonViolPerPop', 'racepctblack', 'FemalePctDiv',\n","       'TotalPctDiv', 'pctWPubAsst', 'pctWInvInc', 'PctYoungKids2Par',\n","       'PctTeen2Par', 'racePctWhite', 'PctFam2Par', 'PctKids2Par',\n","       'ViolentCrimesPerPop']"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['PctKidsBornNeverMar', 'nonViolPerPop', 'racepctblack', 'FemalePctDiv',\n","       'TotalPctDiv', 'pctWPubAsst', 'pctWInvInc', 'PctYoungKids2Par',\n","       'PctTeen2Par', 'racePctWhite', 'PctFam2Par', 'PctKids2Par',\n","       'ViolentCrimesPerPop'],\n","      dtype='object')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df = data.loc[:, [i for i in selected_cols]]\n","df.columns.unique()"]},{"cell_type":"markdown","metadata":{},"source":["Once you have selected a data set, you will produce the deliverables listed below and submit them to one of your peers for review. Treat this exercise as an opportunity to produce analysis that are ready to highlight your analytical skills for a senior audience, for example, the Chief Data Officer, or the Head of Analytics at your company.\n","Sections required in your report:\n","\n","*   Main objective of the analysis that specifies whether your model will be focused on prediction or interpretation.\n","*   Brief description of the data set you chose and a summary of its attributes.\n","*   Brief summary of data exploration and actions taken for data cleaning and feature engineering.\n","*   Summary of training at least three linear regression models which should be variations that cover using a simple  linear regression as a baseline, adding polynomial effects, and using a regularization regression. Preferably, all use the same training and test splits, or the same cross-validation method.\n","*  A paragraph explaining which of your regressions you recommend as a final model that best fits your needs in terms of accuracy and explainability.\n","*  Summary Key Findings and Insights, which walks your reader through the main drivers of your model and insights from your data derived from your linear regression model.\n","*  Suggestions for next steps in analyzing this data, which may include suggesting revisiting this model adding specific data features to achieve a better explanation or a better prediction.\n"]},{"cell_type":"markdown","metadata":{},"source":["# 1. About the Data\n"]},{"cell_type":"markdown","metadata":{},"source":["This is a dataset of 2018 US communities, demographics of each community, and their crime rates. The original dataset has 146 variables where the first four columns are community/location, the middle features are demographic information about each community such as population, age, race, income, and the final columns are types of crimes and overall crime rates.<br>\n","You can find the original dataset [here](https://www.kaggle.com/datasets/michaelbryantds/crimedata)."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["(2215, 13)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2215 entries, 0 to 2214\n","Data columns (total 13 columns):\n"," #   Column               Non-Null Count  Dtype  \n","---  ------               --------------  -----  \n"," 0   PctKidsBornNeverMar  2215 non-null   float64\n"," 1   nonViolPerPop        2118 non-null   float64\n"," 2   racepctblack         2215 non-null   float64\n"," 3   FemalePctDiv         2215 non-null   float64\n"," 4   TotalPctDiv          2215 non-null   float64\n"," 5   pctWPubAsst          2215 non-null   float64\n"," 6   pctWInvInc           2215 non-null   float64\n"," 7   PctYoungKids2Par     2215 non-null   float64\n"," 8   PctTeen2Par          2215 non-null   float64\n"," 9   racePctWhite         2215 non-null   float64\n"," 10  PctFam2Par           2215 non-null   float64\n"," 11  PctKids2Par          2215 non-null   float64\n"," 12  ViolentCrimesPerPop  1994 non-null   float64\n","dtypes: float64(13)\n","memory usage: 225.1 KB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{},"source":["As you can see, the each feature of the dataset is of the type float. The features with missing data is *ViolentCrimesPerPop* and *nonViolPerPop*. *ViolentCrimesPerPop* is our predictor variable. We will handle this before we begin our modelling."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PctKidsBornNeverMar</th>\n","      <th>nonViolPerPop</th>\n","      <th>racepctblack</th>\n","      <th>FemalePctDiv</th>\n","      <th>TotalPctDiv</th>\n","      <th>pctWPubAsst</th>\n","      <th>pctWInvInc</th>\n","      <th>PctYoungKids2Par</th>\n","      <th>PctTeen2Par</th>\n","      <th>racePctWhite</th>\n","      <th>PctFam2Par</th>\n","      <th>PctKids2Par</th>\n","      <th>ViolentCrimesPerPop</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>2215.000000</td>\n","      <td>2118.000000</td>\n","      <td>2215.000000</td>\n","      <td>2215.000000</td>\n","      <td>2215.000000</td>\n","      <td>2215.000000</td>\n","      <td>2215.000000</td>\n","      <td>2215.000000</td>\n","      <td>2215.000000</td>\n","      <td>2215.000000</td>\n","      <td>2215.000000</td>\n","      <td>2215.000000</td>\n","      <td>1994.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>3.115499</td>\n","      <td>4908.241804</td>\n","      <td>9.335102</td>\n","      <td>12.325300</td>\n","      <td>10.812515</td>\n","      <td>6.801445</td>\n","      <td>43.750935</td>\n","      <td>81.865422</td>\n","      <td>75.521788</td>\n","      <td>83.979819</td>\n","      <td>74.059129</td>\n","      <td>71.227255</td>\n","      <td>589.078922</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>3.127681</td>\n","      <td>2739.708901</td>\n","      <td>14.247156</td>\n","      <td>3.262613</td>\n","      <td>3.000883</td>\n","      <td>4.700335</td>\n","      <td>12.787925</td>\n","      <td>12.263736</td>\n","      <td>10.365262</td>\n","      <td>16.419080</td>\n","      <td>10.525952</td>\n","      <td>12.045048</td>\n","      <td>614.784518</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>116.790000</td>\n","      <td>0.000000</td>\n","      <td>3.350000</td>\n","      <td>2.830000</td>\n","      <td>0.180000</td>\n","      <td>5.810000</td>\n","      <td>8.700000</td>\n","      <td>20.200000</td>\n","      <td>2.680000</td>\n","      <td>22.970000</td>\n","      <td>18.300000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.070000</td>\n","      <td>2918.070000</td>\n","      <td>0.860000</td>\n","      <td>9.860000</td>\n","      <td>8.575000</td>\n","      <td>3.270000</td>\n","      <td>34.680000</td>\n","      <td>74.780000</td>\n","      <td>70.170000</td>\n","      <td>76.320000</td>\n","      <td>67.900000</td>\n","      <td>63.990000</td>\n","      <td>161.700000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2.040000</td>\n","      <td>4425.450000</td>\n","      <td>2.870000</td>\n","      <td>12.520000</td>\n","      <td>10.900000</td>\n","      <td>5.610000</td>\n","      <td>42.880000</td>\n","      <td>83.990000</td>\n","      <td>76.920000</td>\n","      <td>90.350000</td>\n","      <td>75.030000</td>\n","      <td>72.530000</td>\n","      <td>374.060000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3.910000</td>\n","      <td>6229.280000</td>\n","      <td>11.145000</td>\n","      <td>14.745000</td>\n","      <td>12.985000</td>\n","      <td>9.105000</td>\n","      <td>52.740000</td>\n","      <td>91.675000</td>\n","      <td>82.765000</td>\n","      <td>96.225000</td>\n","      <td>81.900000</td>\n","      <td>80.395000</td>\n","      <td>794.400000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>27.350000</td>\n","      <td>27119.760000</td>\n","      <td>96.670000</td>\n","      <td>23.920000</td>\n","      <td>22.230000</td>\n","      <td>44.820000</td>\n","      <td>89.040000</td>\n","      <td>100.000000</td>\n","      <td>97.340000</td>\n","      <td>99.630000</td>\n","      <td>93.600000</td>\n","      <td>92.580000</td>\n","      <td>4877.060000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PctKidsBornNeverMar  nonViolPerPop  racepctblack  FemalePctDiv  \\\n","count          2215.000000    2118.000000   2215.000000   2215.000000   \n","mean              3.115499    4908.241804      9.335102     12.325300   \n","std               3.127681    2739.708901     14.247156      3.262613   \n","min               0.000000     116.790000      0.000000      3.350000   \n","25%               1.070000    2918.070000      0.860000      9.860000   \n","50%               2.040000    4425.450000      2.870000     12.520000   \n","75%               3.910000    6229.280000     11.145000     14.745000   \n","max              27.350000   27119.760000     96.670000     23.920000   \n","\n","       TotalPctDiv  pctWPubAsst   pctWInvInc  PctYoungKids2Par  PctTeen2Par  \\\n","count  2215.000000  2215.000000  2215.000000       2215.000000  2215.000000   \n","mean     10.812515     6.801445    43.750935         81.865422    75.521788   \n","std       3.000883     4.700335    12.787925         12.263736    10.365262   \n","min       2.830000     0.180000     5.810000          8.700000    20.200000   \n","25%       8.575000     3.270000    34.680000         74.780000    70.170000   \n","50%      10.900000     5.610000    42.880000         83.990000    76.920000   \n","75%      12.985000     9.105000    52.740000         91.675000    82.765000   \n","max      22.230000    44.820000    89.040000        100.000000    97.340000   \n","\n","       racePctWhite   PctFam2Par  PctKids2Par  ViolentCrimesPerPop  \n","count   2215.000000  2215.000000  2215.000000          1994.000000  \n","mean      83.979819    74.059129    71.227255           589.078922  \n","std       16.419080    10.525952    12.045048           614.784518  \n","min        2.680000    22.970000    18.300000             0.000000  \n","25%       76.320000    67.900000    63.990000           161.700000  \n","50%       90.350000    75.030000    72.530000           374.060000  \n","75%       96.225000    81.900000    80.395000           794.400000  \n","max       99.630000    93.600000    92.580000          4877.060000  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df.describe()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["PctKidsBornNeverMar      0\n","nonViolPerPop           97\n","racepctblack             0\n","FemalePctDiv             0\n","TotalPctDiv              0\n","pctWPubAsst              0\n","pctWInvInc               0\n","PctYoungKids2Par         0\n","PctTeen2Par              0\n","racePctWhite             0\n","PctFam2Par               0\n","PctKids2Par              0\n","ViolentCrimesPerPop    221\n","dtype: int64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Objectives\n"]},{"cell_type":"markdown","metadata":{},"source":["This will be a prediction-based analysis. The main objective of this report is to predict the rates of crime in US communities. <br>\n","This notebook will present a follow-on analysis from the EDA notebook where we performed feature engineering and hypothesis testing as a prelude to this analysis. You can find the EDA notebook [here](https://github.com/Kasheme/Data-Science/blob/main/US-Crime-Communities/US%20Crime%20Notebook%20EDA.ipynb) for reference."]},{"cell_type":"markdown","metadata":{},"source":["# 3. Data Pre-Processing"]},{"cell_type":"markdown","metadata":{},"source":["Brief summary of data exploration and actions taken for data cleaning and feature engineering."]},{"cell_type":"markdown","metadata":{},"source":["# 3. Linear Regression Models\n"]},{"cell_type":"markdown","metadata":{},"source":["Summary of training at least three linear regression models which should be variations that cover using a simple  linear regression as a baseline, adding polynomial effects, and using a regularization regression. Preferably, all use the same training and test splits, or the same cross-validation method."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# 4. Insights and key findings\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# 5. Next Steps\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
